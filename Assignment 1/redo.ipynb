{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import urllib.request\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"iris.tmls\"\n",
    "iris_df = pd.read_csv(data_file)\n",
    "#  drop first row\n",
    "iris_df = iris_df.drop(iris_df.index[0]).reset_index(drop=True)\n",
    "# Convert all columns except the last one (class column) to float\n",
    "iris_df.iloc[:, :-1] = iris_df.iloc[:, :-1].apply(lambda x: x.astype(float))\n",
    "iris_df.head()\n",
    "\n",
    "iris_data_v1 = iris_df[iris_df[\"class\"] != 'Iris-setosa']  # Remove 'Iris-setosa' class\n",
    "iris_data_v2 = iris_df[iris_df[\"class\"] != 'Iris-versicolor']  # Remove 'Iris-versicolor' class\n",
    "iris_data_v3 = iris_df[iris_df[\"class\"] != 'Iris-virginica']  # Remove 'Iris-virginica' class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, test_ratio):\n",
    "    random.shuffle(data)\n",
    "    test_size = int(len(data) * test_ratio)\n",
    "    test_set = data[:test_size]\n",
    "    train_set = data[test_size:]\n",
    "    return train_set, test_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.class_probs = {}\n",
    "        self.feature_probs = {}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Calculate class probabilities\n",
    "        classes = set(y)\n",
    "        for cls in classes:\n",
    "            self.class_probs[cls] = y.count(cls) / len(y)\n",
    "\n",
    "        # Calculate feature probabilities\n",
    "        for cls in classes:\n",
    "            self.feature_probs[cls] = {}\n",
    "            cls_indices = [i for i, label in enumerate(y) if label == cls]\n",
    "            cls_data = [X[i] for i in cls_indices]\n",
    "\n",
    "            for feature_idx in range(len(X[0])):\n",
    "                feature_values = [row[feature_idx] for row in cls_data]\n",
    "                mean = sum(feature_values) / len(feature_values)\n",
    "                variance = sum([(val - mean) ** 2 for val in feature_values]) / len(feature_values)\n",
    "                self.feature_probs[cls][feature_idx] = (mean, variance)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        def gaussian_prob(val, mean, variance):\n",
    "            return (1 / (variance ** 0.5 * (2 * 3.14159) ** 0.5)) * 2.71828 ** (-0.5 * ((val - mean) ** 2 / variance))\n",
    "\n",
    "        probabilities = {}\n",
    "        for cls, cls_prob in self.class_probs.items():\n",
    "            prob = cls_prob\n",
    "            for feature_idx, feature_val in enumerate(x):\n",
    "                mean, variance = self.feature_probs[cls][feature_idx]\n",
    "                prob *= gaussian_prob(feature_val, mean, variance)\n",
    "            probabilities[cls] = prob\n",
    "        return probabilities\n",
    "\n",
    "    def predict(self, x):\n",
    "        probabilities = self.predict_proba(x)\n",
    "        return max(probabilities, key=probabilities.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(data, k):\n",
    "    fold_size = len(data) // k\n",
    "    folds = [data[i * fold_size:(i + 1) * fold_size] for i in range(k)]\n",
    "    return folds\n",
    "\n",
    "def roc_auc(y_true, y_scores, positive_class):\n",
    "    sorted_indices = sorted(range(len(y_scores)), key=lambda i: y_scores[i], reverse=True)\n",
    "    y_sorted = [y_true[i] for i in sorted_indices]\n",
    "\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    num_positive = sum([1 for val in y_true if val == positive_class])\n",
    "    num_negative = len(y_true) - num_positive\n",
    "\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    for val in y_sorted:\n",
    "        if val == positive_class:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "        tpr.append(tp / num_positive)\n",
    "        fpr.append(fp / num_negative)\n",
    "\n",
    "    # Calculate the AUC\n",
    "    auc = 0\n",
    "    for i in range(1, len(tpr)):\n",
    "        auc += (fpr[i] - fpr[i - 1]) * (tpr[i] + tpr[i - 1]) / 2\n",
    "\n",
    "    return fpr, tpr, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39m# Train and evaluate the classifier\u001b[39;00m\n\u001b[0;32m     15\u001b[0m clf \u001b[39m=\u001b[39m NaiveBayesClassifier()\n\u001b[1;32m---> 16\u001b[0m clf\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     17\u001b[0m y_scores \u001b[39m=\u001b[39m [clf\u001b[39m.\u001b[39mpredict_proba(x)[\u001b[39m'\u001b[39m\u001b[39mIris-versicolor\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m X_test]\n\u001b[0;32m     18\u001b[0m fpr, tpr, auc \u001b[39m=\u001b[39m roc_auc(y_test, y_scores, \u001b[39m'\u001b[39m\u001b[39mIris-versicolor\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[19], line 20\u001b[0m, in \u001b[0;36mNaiveBayesClassifier.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mfor\u001b[39;00m feature_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X[\u001b[39m0\u001b[39m])):\n\u001b[0;32m     19\u001b[0m     feature_values \u001b[39m=\u001b[39m [row[feature_idx] \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m cls_data]\n\u001b[1;32m---> 20\u001b[0m     mean \u001b[39m=\u001b[39m \u001b[39msum\u001b[39;49m(feature_values) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(feature_values)\n\u001b[0;32m     21\u001b[0m     variance \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m([(val \u001b[39m-\u001b[39m mean) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39mfor\u001b[39;00m val \u001b[39min\u001b[39;00m feature_values]) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(feature_values)\n\u001b[0;32m     22\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_probs[\u001b[39mcls\u001b[39m][feature_idx] \u001b[39m=\u001b[39m (mean, variance)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "folds = k_fold_cross_validation(iris_data_v1, k)\n",
    "\n",
    "auc_scores = []\n",
    "for i in range(k):\n",
    "    test_set = folds[i]\n",
    "    train_set = [row for j, fold in enumerate(folds) if j != i for row in fold]\n",
    "\n",
    "    X_train = [row[:-1] for row in train_set]\n",
    "    y_train = [row[-1] for row in train_set]\n",
    "    X_test = [row[:-1] for row in test_set]\n",
    "    y_test = [row[-1] for row in test_set]\n",
    "\n",
    "    # Train and evaluate the classifier\n",
    "    clf = NaiveBayesClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_scores = [clf.predict_proba(x)['Iris-versicolor'] for x in X_test]\n",
    "    fpr, tpr, auc = roc_auc(y_test, y_scores, 'Iris-versicolor')\n",
    "    auc_scores.append(auc)\n",
    "\n",
    "average_auc = sum(auc_scores) / len(auc_scores)\n",
    "print(\"10-fold cross-validation average AUC:\", average_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
